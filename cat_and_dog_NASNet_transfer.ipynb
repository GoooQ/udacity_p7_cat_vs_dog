{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战 毕业项目——迁移NASNetMobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始\n",
    "导入一切并我们设置所使用的GPU。\n",
    "- dev1：K40c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/.conda/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#import utilities\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm  \n",
    "from time import time\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from keras import backend as K\n",
    "\n",
    "#如果系统上有多块GPU，“0”可以替换成其它GPU的编号\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据文件处理\n",
    "训练数据包括12500张猫的图片和12500张狗的图片。我们为数据文件建立symbol link并划分为训练集和验证集，所使用的方法参考了[这里](https://github.com/ypwhs/dogs_vs_cats)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 146025.36it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 183339.28it/s]\n"
     ]
    }
   ],
   "source": [
    "#为数据连理symbol-link\n",
    "train_data_dir, valid_data_dir, test_data_dir = prepare_data_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入训练数据和测试数据\n",
    "X_train, Y_train, X_test = load_feature_data(\"feature_NASNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#构造模型并显示所有网络层的名称\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.2525 - acc: 0.8925 - val_loss: 0.1472 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14718, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.1531 - acc: 0.9358 - val_loss: 0.1340 - val_acc: 0.9418\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14718 to 0.13405, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.1375 - acc: 0.9408 - val_loss: 0.1248 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13405 to 0.12478, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1329 - acc: 0.9443 - val_loss: 0.1139 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12478 to 0.11393, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.1299 - acc: 0.9437 - val_loss: 0.1113 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11393 to 0.11130, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.1270 - acc: 0.9470 - val_loss: 0.1098 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11130 to 0.10984, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.1254 - acc: 0.9463 - val_loss: 0.1109 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.1253 - acc: 0.9471 - val_loss: 0.1069 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10984 to 0.10686, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1250 - acc: 0.9455 - val_loss: 0.1074 - val_acc: 0.9534\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1248 - acc: 0.9484 - val_loss: 0.1072 - val_acc: 0.9526\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1216 - acc: 0.9495 - val_loss: 0.1090 - val_acc: 0.9516\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1223 - acc: 0.9510 - val_loss: 0.1095 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1222 - acc: 0.9487 - val_loss: 0.1042 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.10686 to 0.10424, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1217 - acc: 0.9496 - val_loss: 0.1045 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1220 - acc: 0.9475 - val_loss: 0.1080 - val_acc: 0.9530\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1218 - acc: 0.9472 - val_loss: 0.1041 - val_acc: 0.9554\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.10424 to 0.10405, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1198 - acc: 0.9491 - val_loss: 0.1067 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1212 - acc: 0.9470 - val_loss: 0.1032 - val_acc: 0.9548\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.10405 to 0.10318, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1195 - acc: 0.9493 - val_loss: 0.1031 - val_acc: 0.9564\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.10318 to 0.10309, saving model to nasnet-tune0-best_weight.h5\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.1181 - acc: 0.9507 - val_loss: 0.1041 - val_acc: 0.9566\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5cba3d3b00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并导出权重参数\n",
    "filepath=\"nasnet-tune0-best_weight.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, validation_split=0.2, shuffle=True,\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 0s 25us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/DLND/Cat_vs_Dog/helper.py:130: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(index-1, 'label', y_test[i])\n"
     ]
    }
   ],
   "source": [
    "#在测试集上进行预测并导出预测值\n",
    "predict_on_model(test_data_dir, X_test, model, \"pred-nasnet-tune0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这一模型在Kaggle上的得分为0.12040"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
