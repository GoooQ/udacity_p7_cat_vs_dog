{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战 毕业项目——Fine-tuning ResNet50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始\n",
    "导入一切并我们设置所使用的GPU。\n",
    "- dev0: GTX1070Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/.conda/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#import utilities\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm  \n",
    "from time import time\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from keras import backend as K\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据文件处理\n",
    "训练数据包括12500张猫的图片和12500张狗的图片。我们为数据文件建立symbol link并划分为训练集和验证集，所使用的方法参考了[这里](https://github.com/ypwhs/dogs_vs_cats)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 164943.06it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 188439.61it/s]\n"
     ]
    }
   ],
   "source": [
    "#为数据连理symbol-link\n",
    "train_data_dir, test_data_dir = prepare_data_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基准模型\n",
    "作为迁移学习的基础，这里我们使用ResNet50为基准模型：\n",
    "- [ResNet](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "在导出预训练模型特征时，我们所使用的方法参考了[这里](https://github.com/ypwhs/dogs_vs_cats)。\n",
    "\n",
    "我们首先冻结所有Resnet的权重参数，只训练全链接层。我们在融合模型中已经导出了所有训练数据和测试数据在Resnet上的特征，基于这些特征，我们训练猫狗问题的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入训练数据和测试数据\n",
    "X_train, Y_train, X_test = load_feature_data(\"feature_resnet50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#构造模型并显示所有网络层的名称\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 0s 13us/step - loss: 0.0663 - acc: 0.9743 - val_loss: 0.0564 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05638, saving model to resnet50-tune0-best_weight.h5\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0691 - acc: 0.9743 - val_loss: 0.0562 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05638 to 0.05624, saving model to resnet50-tune0-best_weight.h5\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 0s 14us/step - loss: 0.0673 - acc: 0.9748 - val_loss: 0.0592 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0648 - acc: 0.9754 - val_loss: 0.0569 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0655 - acc: 0.9748 - val_loss: 0.0633 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0658 - acc: 0.9751 - val_loss: 0.0557 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05624 to 0.05566, saving model to resnet50-tune0-best_weight.h5\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0652 - acc: 0.9755 - val_loss: 0.0646 - val_acc: 0.9760\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0651 - acc: 0.9751 - val_loss: 0.0598 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0645 - acc: 0.9752 - val_loss: 0.0607 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0660 - acc: 0.9745 - val_loss: 0.0561 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0644 - acc: 0.9760 - val_loss: 0.0573 - val_acc: 0.9784\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0660 - acc: 0.9751 - val_loss: 0.0705 - val_acc: 0.9744\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0624 - acc: 0.9761 - val_loss: 0.0569 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0663 - acc: 0.9732 - val_loss: 0.0594 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 0s 20us/step - loss: 0.0617 - acc: 0.9768 - val_loss: 0.0559 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.0639 - acc: 0.9768 - val_loss: 0.0561 - val_acc: 0.9790\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.0654 - acc: 0.9745 - val_loss: 0.0609 - val_acc: 0.9782\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.0606 - acc: 0.9761 - val_loss: 0.0565 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.0672 - acc: 0.9738 - val_loss: 0.0570 - val_acc: 0.9796\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 0s 23us/step - loss: 0.0662 - acc: 0.9756 - val_loss: 0.0556 - val_acc: 0.9806\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05566 to 0.05558, saving model to resnet50-tune0-best_weight.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9aa00bd160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并导出权重参数\n",
    "filepath=\"resnet50-tune0-best_weight.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, validation_split=0.2, shuffle=True,\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 0s 32us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/DLND/Cat_vs_Dog/helper.py:115: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(index-1, 'label', y_test[i])\n"
     ]
    }
   ],
   "source": [
    "#在测试集上进行预测并导出预测值\n",
    "predict_on_model(test_data_dir, X_test, model, \"pred-resnet50-tune0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一模型在Kaggle上的得分为0.07529，还不错。下一步我们将开始Fine-tuning基于Resnet50的猫狗分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "我们将放开Resnet50中的一些单元的权值，让它们是可学习的，以此训练我们的猫狗分类网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune 0\n",
    "这里，我们首先在冻结全部权重情况下对全链接层进行训练。我们引入数据增强以获得更为泛化的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 bn_conv1\n",
      "4 activation_1\n",
      "5 max_pooling2d_1\n",
      "6 res2a_branch2a\n",
      "7 bn2a_branch2a\n",
      "8 activation_2\n",
      "9 res2a_branch2b\n",
      "10 bn2a_branch2b\n",
      "11 activation_3\n",
      "12 res2a_branch2c\n",
      "13 res2a_branch1\n",
      "14 bn2a_branch2c\n",
      "15 bn2a_branch1\n",
      "16 add_1\n",
      "17 activation_4\n",
      "18 res2b_branch2a\n",
      "19 bn2b_branch2a\n",
      "20 activation_5\n",
      "21 res2b_branch2b\n",
      "22 bn2b_branch2b\n",
      "23 activation_6\n",
      "24 res2b_branch2c\n",
      "25 bn2b_branch2c\n",
      "26 add_2\n",
      "27 activation_7\n",
      "28 res2c_branch2a\n",
      "29 bn2c_branch2a\n",
      "30 activation_8\n",
      "31 res2c_branch2b\n",
      "32 bn2c_branch2b\n",
      "33 activation_9\n",
      "34 res2c_branch2c\n",
      "35 bn2c_branch2c\n",
      "36 add_3\n",
      "37 activation_10\n",
      "38 res3a_branch2a\n",
      "39 bn3a_branch2a\n",
      "40 activation_11\n",
      "41 res3a_branch2b\n",
      "42 bn3a_branch2b\n",
      "43 activation_12\n",
      "44 res3a_branch2c\n",
      "45 res3a_branch1\n",
      "46 bn3a_branch2c\n",
      "47 bn3a_branch1\n",
      "48 add_4\n",
      "49 activation_13\n",
      "50 res3b_branch2a\n",
      "51 bn3b_branch2a\n",
      "52 activation_14\n",
      "53 res3b_branch2b\n",
      "54 bn3b_branch2b\n",
      "55 activation_15\n",
      "56 res3b_branch2c\n",
      "57 bn3b_branch2c\n",
      "58 add_5\n",
      "59 activation_16\n",
      "60 res3c_branch2a\n",
      "61 bn3c_branch2a\n",
      "62 activation_17\n",
      "63 res3c_branch2b\n",
      "64 bn3c_branch2b\n",
      "65 activation_18\n",
      "66 res3c_branch2c\n",
      "67 bn3c_branch2c\n",
      "68 add_6\n",
      "69 activation_19\n",
      "70 res3d_branch2a\n",
      "71 bn3d_branch2a\n",
      "72 activation_20\n",
      "73 res3d_branch2b\n",
      "74 bn3d_branch2b\n",
      "75 activation_21\n",
      "76 res3d_branch2c\n",
      "77 bn3d_branch2c\n",
      "78 add_7\n",
      "79 activation_22\n",
      "80 res4a_branch2a\n",
      "81 bn4a_branch2a\n",
      "82 activation_23\n",
      "83 res4a_branch2b\n",
      "84 bn4a_branch2b\n",
      "85 activation_24\n",
      "86 res4a_branch2c\n",
      "87 res4a_branch1\n",
      "88 bn4a_branch2c\n",
      "89 bn4a_branch1\n",
      "90 add_8\n",
      "91 activation_25\n",
      "92 res4b_branch2a\n",
      "93 bn4b_branch2a\n",
      "94 activation_26\n",
      "95 res4b_branch2b\n",
      "96 bn4b_branch2b\n",
      "97 activation_27\n",
      "98 res4b_branch2c\n",
      "99 bn4b_branch2c\n",
      "100 add_9\n",
      "101 activation_28\n",
      "102 res4c_branch2a\n",
      "103 bn4c_branch2a\n",
      "104 activation_29\n",
      "105 res4c_branch2b\n",
      "106 bn4c_branch2b\n",
      "107 activation_30\n",
      "108 res4c_branch2c\n",
      "109 bn4c_branch2c\n",
      "110 add_10\n",
      "111 activation_31\n",
      "112 res4d_branch2a\n",
      "113 bn4d_branch2a\n",
      "114 activation_32\n",
      "115 res4d_branch2b\n",
      "116 bn4d_branch2b\n",
      "117 activation_33\n",
      "118 res4d_branch2c\n",
      "119 bn4d_branch2c\n",
      "120 add_11\n",
      "121 activation_34\n",
      "122 res4e_branch2a\n",
      "123 bn4e_branch2a\n",
      "124 activation_35\n",
      "125 res4e_branch2b\n",
      "126 bn4e_branch2b\n",
      "127 activation_36\n",
      "128 res4e_branch2c\n",
      "129 bn4e_branch2c\n",
      "130 add_12\n",
      "131 activation_37\n",
      "132 res4f_branch2a\n",
      "133 bn4f_branch2a\n",
      "134 activation_38\n",
      "135 res4f_branch2b\n",
      "136 bn4f_branch2b\n",
      "137 activation_39\n",
      "138 res4f_branch2c\n",
      "139 bn4f_branch2c\n",
      "140 add_13\n",
      "141 activation_40\n",
      "142 res5a_branch2a\n",
      "143 bn5a_branch2a\n",
      "144 activation_41\n",
      "145 res5a_branch2b\n",
      "146 bn5a_branch2b\n",
      "147 activation_42\n",
      "148 res5a_branch2c\n",
      "149 res5a_branch1\n",
      "150 bn5a_branch2c\n",
      "151 bn5a_branch1\n",
      "152 add_14\n",
      "153 activation_43\n",
      "154 res5b_branch2a\n",
      "155 bn5b_branch2a\n",
      "156 activation_44\n",
      "157 res5b_branch2b\n",
      "158 bn5b_branch2b\n",
      "159 activation_45\n",
      "160 res5b_branch2c\n",
      "161 bn5b_branch2c\n",
      "162 add_15\n",
      "163 activation_46\n",
      "164 res5c_branch2a\n",
      "165 bn5c_branch2a\n",
      "166 activation_47\n",
      "167 res5c_branch2b\n",
      "168 bn5c_branch2b\n",
      "169 activation_48\n",
      "170 res5c_branch2c\n",
      "171 bn5c_branch2c\n",
      "172 add_16\n",
      "173 activation_49\n",
      "174 avg_pool\n",
      "175 global_average_pooling2d_1\n",
      "176 dropout_1\n",
      "177 dense_1\n"
     ]
    }
   ],
   "source": [
    "#构造模型\n",
    "x_input = Input((224, 224, 3))\n",
    "x_input = Lambda(xception.preprocess_input)(x_input)\n",
    "\n",
    "base_model = ResNet50(input_tensor=x_input, weights='imagenet', include_top=False, pooling = 'avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Dropout(0.5)(base_model.output)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, x)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    print(i,model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 0.0956 - acc: 0.9650 - val_loss: 0.1223 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12233, saving model to resnet50-best_weight_freeze.h5\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 119s 190ms/step - loss: 0.0902 - acc: 0.9661 - val_loss: 0.1136 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12233 to 0.11362, saving model to resnet50-best_weight_freeze.h5\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 0.0894 - acc: 0.9639 - val_loss: 0.1168 - val_acc: 0.9629\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 0.0901 - acc: 0.9665 - val_loss: 0.1169 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 0.0945 - acc: 0.9644 - val_loss: 0.1215 - val_acc: 0.9646\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 119s 190ms/step - loss: 0.0915 - acc: 0.9665 - val_loss: 0.1250 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 120s 192ms/step - loss: 0.0909 - acc: 0.9642 - val_loss: 0.1197 - val_acc: 0.9625\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 0.0876 - acc: 0.9669 - val_loss: 0.1588 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 119s 191ms/step - loss: 0.0868 - acc: 0.9677 - val_loss: 0.1062 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11362 to 0.10617, saving model to resnet50-best_weight_freeze.h5\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 120s 191ms/step - loss: 0.0921 - acc: 0.9650 - val_loss: 0.1175 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99ef6a3f98>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "gen = ImageDataGenerator(validation_split=0.2)\n",
    "train_generator = gen.flow_from_directory(train_data_dir, (224, 224), shuffle=True, \n",
    "                                          batch_size=32,class_mode='binary')\n",
    "filepath=\"resnet50-best_weight_freeze.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=625,\n",
    "        epochs=10,\n",
    "        validation_data=train_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:39<00:00, 317.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 65s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:133: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 257512.64it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_resnet(12500, 224, 224, test_data_dir, model, \"resnet50-best_weight_freeze.h5\", \"pred-resnet50-freeze.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模型在kaggle的得分是0.12619。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 1\n",
    "开放162层以上的权重优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[162:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights('resnet50-best_weight_freeze.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 125s 200ms/step - loss: 0.0766 - acc: 0.9715 - val_loss: 0.0486 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04864, saving model to resnet50-best_weight_fine_tuning-1.h5\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 124s 198ms/step - loss: 0.0528 - acc: 0.9808 - val_loss: 0.1321 - val_acc: 0.9615\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 124s 198ms/step - loss: 0.0428 - acc: 0.9833 - val_loss: 0.0467 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04864 to 0.04666, saving model to resnet50-best_weight_fine_tuning-1.h5\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 124s 198ms/step - loss: 0.0325 - acc: 0.9877 - val_loss: 0.0727 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 124s 198ms/step - loss: 0.0274 - acc: 0.9906 - val_loss: 0.0357 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04666 to 0.03573, saving model to resnet50-best_weight_fine_tuning-1.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa002374eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "gen = ImageDataGenerator(rotation_range=40,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True,\n",
    "                        validation_split=0.2)\n",
    "train_generator = gen.flow_from_directory(train_data_dir, (224, 224), shuffle=True, \n",
    "                                          batch_size=32,class_mode='binary')\n",
    "\n",
    "filepath=\"resnet50-best_weight_fine_tuning-1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=625,\n",
    "        epochs=5,\n",
    "        validation_data=train_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:38<00:00, 323.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 64s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:133: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 257554.38it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_resnet(12500, 224, 224, test_data_dir, model, \"resnet50-best_weight_fine_tuning-1.h5\", \"pred-resnet50-fine_tuning-1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一轮Tuning的最终得分为：0.07575。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 2\n",
    "开放152层以上的权重优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[152:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights('resnet50-best_weight_fine_tuning-1.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 133s 212ms/step - loss: 0.0362 - acc: 0.9885 - val_loss: 0.0357 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03565, saving model to resnet50-best_weight_fine_tuning-2.h5\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 0.0191 - acc: 0.9935 - val_loss: 0.0275 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03565 to 0.02745, saving model to resnet50-best_weight_fine_tuning-2.h5\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0538 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0277 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 132s 211ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0651 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fcac58b38>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=40,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True,\n",
    "                        validation_split=0.2)\n",
    "train_generator = gen.flow_from_directory(train_data_dir, (224, 224), shuffle=True, \n",
    "                                          batch_size=32,class_mode='binary')\n",
    "\n",
    "filepath=\"resnet50-best_weight_fine_tuning-2.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=625,\n",
    "        epochs=5,\n",
    "        validation_data=train_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:38<00:00, 322.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 64s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:133: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 254873.73it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_resnet(12500, 224, 224, test_data_dir, model, \"resnet50-best_weight_fine_tuning-2.h5\", \"pred-resnet50-fine_tuning-2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从loss上看，这个模型已经有点过拟合了，不过没关系，我们只是把它所谓增强模型的初始值。这一轮Tuning的最终得分为：0.07564。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 3\n",
    "开放140层以上的权重优化。同时，我们对图片生成器进行增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[140:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights('resnet50-best_weight_fine_tuning-2.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 703s 563ms/step - loss: 0.0619 - acc: 0.9765 - val_loss: 0.0883 - val_acc: 0.9678\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08826, saving model to resnet50-best_weight_fine_tuning-3.h5\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 695s 556ms/step - loss: 0.0352 - acc: 0.9866 - val_loss: 0.0586 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08826 to 0.05857, saving model to resnet50-best_weight_fine_tuning-3.h5\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 695s 556ms/step - loss: 0.0243 - acc: 0.9912 - val_loss: 0.0510 - val_acc: 0.9814\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05857 to 0.05105, saving model to resnet50-best_weight_fine_tuning-3.h5\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 695s 556ms/step - loss: 0.0198 - acc: 0.9927 - val_loss: 0.0561 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 694s 555ms/step - loss: 0.0159 - acc: 0.9941 - val_loss: 0.0657 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 695s 556ms/step - loss: 0.0147 - acc: 0.9951 - val_loss: 0.0473 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05105 to 0.04726, saving model to resnet50-best_weight_fine_tuning-3.h5\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 697s 558ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 0.0772 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 696s 556ms/step - loss: 0.0100 - acc: 0.9965 - val_loss: 0.0478 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 696s 557ms/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0510 - val_acc: 0.9830\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 694s 555ms/step - loss: 0.0095 - acc: 0.9967 - val_loss: 0.0566 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa0037cec50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=40,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True,\n",
    "                        validation_split=0.2)\n",
    "\n",
    "train_generator = gen.flow_from_directory(train_data_dir, (224, 224), shuffle=True, \n",
    "                                          batch_size=64,class_mode='binary')\n",
    "filepath=\"resnet50-best_weight_fine_tuning-3.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1250,\n",
    "        epochs=10,\n",
    "        validation_data=train_generator,\n",
    "        validation_steps=300,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:38<00:00, 322.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 64s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:133: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 255382.74it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_resnet(12500, 224, 224, test_data_dir, model, \"resnet50-best_weight_fine_tuning-3.h5\", \"pred-resnet50-fine_tuning-3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终，Fine tuning的得分为：0.07259。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存效果最好的那个模型\n",
    "从最终的得分看出，目前效果最好的模型是Fine-tuning-2。我们载入全部模型，并将基础模型部分的权重分开保存起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(input_tensor=Input((224, 224, 3)), weights='imagenet', include_top=False, pooling = 'avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Dropout(0.5)(base_model.output)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, x)\n",
    "model.load_weights('resnet50-best_weight_fine_tuning-3.h5')\n",
    "\n",
    "base_model.save_weights(\"fine_tuned_resnet50.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
