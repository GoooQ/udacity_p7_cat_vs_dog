{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战 毕业项目——Fine-tuning Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始\n",
    "导入一切并我们设置所使用的GPU。\n",
    "- dev0: GTX1070Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/.conda/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#import utilities\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm  \n",
    "from time import time\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from keras import backend as K\n",
    "\n",
    "#如果系统上有多块GPU，“0”可以替换成其它GPU的编号\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据文件处理\n",
    "训练数据包括12500张猫的图片和12500张狗的图片。我们为数据文件建立symbol link并划分为训练集和验证集，所使用的方法参考了[这里](https://github.com/ypwhs/dogs_vs_cats)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 150667.65it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 189498.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#为数据连理symbol-link\n",
    "train_data_dir, valid_data_dir, test_data_dir = prepare_data_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基准模型\n",
    "作为迁移学习的基础，这里我们使用Xception为基准模型：\n",
    "- [Xception](https://arxiv.org/abs/1610.02357)\n",
    "\n",
    "在导出预训练模型特征时，我们所使用的方法参考了[这里](https://github.com/ypwhs/dogs_vs_cats)。\n",
    "\n",
    "我们首先冻结所有Xception的权重参数，只训练全链接层。我们在融合模型中已经导出了所有训练数据和测试数据在Xception上的特征，基于这些特征，我们训练猫狗问题的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入训练数据和测试数据\n",
    "X_train, Y_train, X_test = load_feature_data(\"feature_xception.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#构造模型并显示所有网络层的名称\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.1565 - acc: 0.9689 - val_loss: 0.0468 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04683, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 0.0407 - acc: 0.9911 - val_loss: 0.0246 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04683 to 0.02456, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 0.0287 - acc: 0.9922 - val_loss: 0.0194 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02456 to 0.01939, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0252 - acc: 0.9926 - val_loss: 0.0168 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01939 to 0.01680, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0241 - acc: 0.9924 - val_loss: 0.0157 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01680 to 0.01571, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0216 - acc: 0.9932 - val_loss: 0.0150 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01571 to 0.01496, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0216 - acc: 0.9936 - val_loss: 0.0143 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01496 to 0.01434, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0211 - acc: 0.9937 - val_loss: 0.0141 - val_acc: 0.9958\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01434 to 0.01406, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0205 - acc: 0.9935 - val_loss: 0.0136 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01406 to 0.01358, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 0.0199 - acc: 0.9938 - val_loss: 0.0132 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01358 to 0.01324, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0131 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01324 to 0.01305, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0129 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01305 to 0.01287, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0196 - acc: 0.9940 - val_loss: 0.0128 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01287 to 0.01276, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 0.0188 - acc: 0.9940 - val_loss: 0.0126 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01276 to 0.01264, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0125 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01264 to 0.01252, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0181 - acc: 0.9942 - val_loss: 0.0123 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01252 to 0.01231, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.0122 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01231 to 0.01219, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 0.0189 - acc: 0.9933 - val_loss: 0.0123 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 1s 26us/step - loss: 0.0174 - acc: 0.9946 - val_loss: 0.0120 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01219 to 0.01200, saving model to xception-tune0-best_weight.h5\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 1s 27us/step - loss: 0.0176 - acc: 0.9940 - val_loss: 0.0120 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7facdfe3f3c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并导出权重参数\n",
    "filepath=\"xception-tune0-best_weight.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, validation_split=0.2, shuffle=True,\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 0s 29us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/DLND/Cat_vs_Dog/helper.py:130: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(index-1, 'label', y_test[i])\n"
     ]
    }
   ],
   "source": [
    "#在测试集上进行预测并导出预测值\n",
    "predict_on_model(test_data_dir, X_test, model, \"pred-xception-tune0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这一模型在Kaggle上的得分为0.04091，非常高的一个分数。下一步我们将开始Fine-tuning基于Xception的猫狗分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "我们将放开Xception中的一些单元的权值，让它们是可学习的，以此训练我们的猫狗分类网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune freeze\n",
    "这里，我们首先在冻结全部权重情况下对全链接层进行训练。我们引入数据增强以获得更为泛化的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "0 input_1\n",
      "1 lambda_1\n",
      "2 block1_conv1\n",
      "3 block1_conv1_bn\n",
      "4 block1_conv1_act\n",
      "5 block1_conv2\n",
      "6 block1_conv2_bn\n",
      "7 block1_conv2_act\n",
      "8 block2_sepconv1\n",
      "9 block2_sepconv1_bn\n",
      "10 block2_sepconv2_act\n",
      "11 block2_sepconv2\n",
      "12 block2_sepconv2_bn\n",
      "13 conv2d_1\n",
      "14 block2_pool\n",
      "15 batch_normalization_1\n",
      "16 add_1\n",
      "17 block3_sepconv1_act\n",
      "18 block3_sepconv1\n",
      "19 block3_sepconv1_bn\n",
      "20 block3_sepconv2_act\n",
      "21 block3_sepconv2\n",
      "22 block3_sepconv2_bn\n",
      "23 conv2d_2\n",
      "24 block3_pool\n",
      "25 batch_normalization_2\n",
      "26 add_2\n",
      "27 block4_sepconv1_act\n",
      "28 block4_sepconv1\n",
      "29 block4_sepconv1_bn\n",
      "30 block4_sepconv2_act\n",
      "31 block4_sepconv2\n",
      "32 block4_sepconv2_bn\n",
      "33 conv2d_3\n",
      "34 block4_pool\n",
      "35 batch_normalization_3\n",
      "36 add_3\n",
      "37 block5_sepconv1_act\n",
      "38 block5_sepconv1\n",
      "39 block5_sepconv1_bn\n",
      "40 block5_sepconv2_act\n",
      "41 block5_sepconv2\n",
      "42 block5_sepconv2_bn\n",
      "43 block5_sepconv3_act\n",
      "44 block5_sepconv3\n",
      "45 block5_sepconv3_bn\n",
      "46 add_4\n",
      "47 block6_sepconv1_act\n",
      "48 block6_sepconv1\n",
      "49 block6_sepconv1_bn\n",
      "50 block6_sepconv2_act\n",
      "51 block6_sepconv2\n",
      "52 block6_sepconv2_bn\n",
      "53 block6_sepconv3_act\n",
      "54 block6_sepconv3\n",
      "55 block6_sepconv3_bn\n",
      "56 add_5\n",
      "57 block7_sepconv1_act\n",
      "58 block7_sepconv1\n",
      "59 block7_sepconv1_bn\n",
      "60 block7_sepconv2_act\n",
      "61 block7_sepconv2\n",
      "62 block7_sepconv2_bn\n",
      "63 block7_sepconv3_act\n",
      "64 block7_sepconv3\n",
      "65 block7_sepconv3_bn\n",
      "66 add_6\n",
      "67 block8_sepconv1_act\n",
      "68 block8_sepconv1\n",
      "69 block8_sepconv1_bn\n",
      "70 block8_sepconv2_act\n",
      "71 block8_sepconv2\n",
      "72 block8_sepconv2_bn\n",
      "73 block8_sepconv3_act\n",
      "74 block8_sepconv3\n",
      "75 block8_sepconv3_bn\n",
      "76 add_7\n",
      "77 block9_sepconv1_act\n",
      "78 block9_sepconv1\n",
      "79 block9_sepconv1_bn\n",
      "80 block9_sepconv2_act\n",
      "81 block9_sepconv2\n",
      "82 block9_sepconv2_bn\n",
      "83 block9_sepconv3_act\n",
      "84 block9_sepconv3\n",
      "85 block9_sepconv3_bn\n",
      "86 add_8\n",
      "87 block10_sepconv1_act\n",
      "88 block10_sepconv1\n",
      "89 block10_sepconv1_bn\n",
      "90 block10_sepconv2_act\n",
      "91 block10_sepconv2\n",
      "92 block10_sepconv2_bn\n",
      "93 block10_sepconv3_act\n",
      "94 block10_sepconv3\n",
      "95 block10_sepconv3_bn\n",
      "96 add_9\n",
      "97 block11_sepconv1_act\n",
      "98 block11_sepconv1\n",
      "99 block11_sepconv1_bn\n",
      "100 block11_sepconv2_act\n",
      "101 block11_sepconv2\n",
      "102 block11_sepconv2_bn\n",
      "103 block11_sepconv3_act\n",
      "104 block11_sepconv3\n",
      "105 block11_sepconv3_bn\n",
      "106 add_10\n",
      "107 block12_sepconv1_act\n",
      "108 block12_sepconv1\n",
      "109 block12_sepconv1_bn\n",
      "110 block12_sepconv2_act\n",
      "111 block12_sepconv2\n",
      "112 block12_sepconv2_bn\n",
      "113 block12_sepconv3_act\n",
      "114 block12_sepconv3\n",
      "115 block12_sepconv3_bn\n",
      "116 add_11\n",
      "117 block13_sepconv1_act\n",
      "118 block13_sepconv1\n",
      "119 block13_sepconv1_bn\n",
      "120 block13_sepconv2_act\n",
      "121 block13_sepconv2\n",
      "122 block13_sepconv2_bn\n",
      "123 conv2d_4\n",
      "124 block13_pool\n",
      "125 batch_normalization_4\n",
      "126 add_12\n",
      "127 block14_sepconv1\n",
      "128 block14_sepconv1_bn\n",
      "129 block14_sepconv1_act\n",
      "130 block14_sepconv2\n",
      "131 block14_sepconv2_bn\n",
      "132 block14_sepconv2_act\n",
      "133 global_average_pooling2d_1\n",
      "134 dropout_1\n",
      "135 dense_1\n"
     ]
    }
   ],
   "source": [
    "#构造模型\n",
    "x_input = Input((299, 299, 3))\n",
    "x_input = Lambda(xception.preprocess_input)(x_input)\n",
    "\n",
    "base_model = Xception(input_tensor=x_input, weights='imagenet', include_top=False, pooling = 'avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Dropout(0.5)(base_model.output)\n",
    "x = Dense(1, activation='sigmoid',kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "model = Model(base_model.input, x)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=90,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True)\n",
    "val_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow_from_directory(train_data_dir, (299, 299), shuffle=True, \n",
    "                                          batch_size=64,class_mode='binary')\n",
    "valid_generator = val_gen.flow_from_directory(valid_data_dir, (299, 299), shuffle=True, \n",
    "                                          batch_size=32,class_mode='binary')\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    print(i,model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 510s 815ms/step - loss: 0.1936 - acc: 0.9349 - val_loss: 0.0794 - val_acc: 0.9846\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07936, saving model to xception-best_weight_freeze.h5\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 513s 821ms/step - loss: 0.1408 - acc: 0.9500 - val_loss: 0.0816 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 511s 818ms/step - loss: 0.1366 - acc: 0.9517 - val_loss: 0.0618 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07936 to 0.06180, saving model to xception-best_weight_freeze.h5\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 513s 821ms/step - loss: 0.1322 - acc: 0.9536 - val_loss: 0.0849 - val_acc: 0.9819\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 511s 817ms/step - loss: 0.1360 - acc: 0.9519 - val_loss: 0.0788 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efcc314de10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "filepath=\"xception-best_weight_freeze.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=625,\n",
    "        epochs=5,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:43<00:00, 287.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 127s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:166: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 237378.32it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_xception(12500, 299, 299, test_data_dir, model, \"xception-best_weight_freeze.h5\", \"pred-xception-freeze.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这个模型在kaggle的得分是0.07127。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 1\n",
    "开放97层以上的权重优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[97:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights('xception-best_weight_freeze.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 999s 799ms/step - loss: 0.0547 - acc: 0.9819 - val_loss: 0.0205 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02055, saving model to xception-best_weight_fine_tuning-1.h5\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 996s 797ms/step - loss: 0.0253 - acc: 0.9925 - val_loss: 0.0187 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02055 to 0.01867, saving model to xception-best_weight_fine_tuning-1.h5\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 997s 797ms/step - loss: 0.0170 - acc: 0.9950 - val_loss: 0.0162 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01867 to 0.01621, saving model to xception-best_weight_fine_tuning-1.h5\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 997s 798ms/step - loss: 0.0140 - acc: 0.9961 - val_loss: 0.0196 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 1004s 803ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0219 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efcc39c64a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "filepath=\"xception-best_weight_fine_tuning-1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1250,\n",
    "        epochs=5,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:43<00:00, 288.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6496/12500 [==============>...............] - ETA: 1:02"
     ]
    }
   ],
   "source": [
    "predict_on_xception(12500, 299, 299, test_data_dir, model, \"xception-best_weight_fine_tuning-1.h5\", \"pred-xception-fine_tuning-1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这一轮Tuning的最终得分为：0.03600。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 2\n",
    "开放107层以上的权重优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[107:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights('xception-best_weight_fine_tuning-1.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 991s 793ms/step - loss: 0.0123 - acc: 0.9964 - val_loss: 0.0228 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02279, saving model to xception-best_weight_fine_tuning-2.h5\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 992s 794ms/step - loss: 0.0102 - acc: 0.9971 - val_loss: 0.0263 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 988s 790ms/step - loss: 0.0091 - acc: 0.9977 - val_loss: 0.0259 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 989s 791ms/step - loss: 0.0080 - acc: 0.9980 - val_loss: 0.0166 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02279 to 0.01660, saving model to xception-best_weight_fine_tuning-2.h5\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 988s 791ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0243 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efdc6a86390>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"xception-best_weight_fine_tuning-2.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1250,\n",
    "        epochs=5,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:43<00:00, 288.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 129s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:166: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 242560.85it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_xception(12500, 299, 299, test_data_dir, model, \"xception-best_weight_fine_tuning-2.h5\", \"pred-xception-fine_tuning-2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这一轮Tuning的最终得分为：0.03780。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 3\n",
    "开放87层以上的权重优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[87:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights('xception-best_weight_fine_tuning-1.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - 1085s 868ms/step - loss: 0.0153 - acc: 0.9957 - val_loss: 0.0175 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01750, saving model to xception-best_weight_fine_tuning-3.h5\n",
      "Epoch 2/5\n",
      "1250/1250 [==============================] - 1084s 867ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.0225 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      "1250/1250 [==============================] - 1084s 867ms/step - loss: 0.0093 - acc: 0.9977 - val_loss: 0.0207 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      "1250/1250 [==============================] - 1084s 867ms/step - loss: 0.0079 - acc: 0.9980 - val_loss: 0.0234 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      "1250/1250 [==============================] - 1084s 867ms/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.0178 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4ea393d588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"xception-best_weight_fine_tuning-3.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1250,\n",
    "        epochs=5,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:43<00:00, 286.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 129s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:166: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 247713.45it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_xception(12500, 299, 299, test_data_dir, model, \"xception-best_weight_fine_tuning-3.h5\", \"pred-xception-fine_tuning-3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终，Fine tuning的得分为：0.03770。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存效果最好的那个模型\n",
    "从最终的得分看出，目前效果最好的模型是Fine-tuning-2。我们载入全部模型，并将基础模型部分的权重分开保存起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_weights(\"fine_tuned_xception.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
