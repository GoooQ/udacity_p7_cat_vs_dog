{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗大战 毕业项目——Fine-tuning DenseNet169"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始\n",
    "导入一切并我们设置所使用的GPU。\n",
    "- dev0: GTX1070Ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/.conda/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#import utilities\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm  \n",
    "from time import time\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from helper import *\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils import *\n",
    "from keras import backend as K\n",
    "\n",
    "#如果系统上有多块GPU，“0”可以替换成其它GPU的编号\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据文件处理\n",
    "训练数据包括12500张猫的图片和12500张狗的图片。我们为数据文件建立symbol link并划分为训练集和验证集，所使用的方法参考了[这里](https://github.com/ypwhs/dogs_vs_cats)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:00<00:00, 148120.90it/s]\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 183990.40it/s]\n"
     ]
    }
   ],
   "source": [
    "#为数据连理symbol-link\n",
    "train_data_dir, valid_data_dir, test_data_dir = prepare_data_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基准模型\n",
    "作为迁移学习的基础，这里我们使用DenseNet169为基准模型：\n",
    "- [DenseNet](https://arxiv.org/abs/1608.06993)\n",
    "\n",
    "在导出预训练模型特征时，我们所使用的方法参考了[这里](https://github.com/ypwhs/dogs_vs_cats)。\n",
    "\n",
    "我们首先冻结所有DenseNet的权重参数，只训练全链接层。我们在融合模型中已经导出了所有训练数据和测试数据在DenseNet上的特征，基于这些特征，我们训练猫狗问题的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入训练数据和测试数据\n",
    "X_train, Y_train, X_test = load_feature_data(\"feature_densenet169.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#构造模型并显示所有网络层的名称\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 0.1397 - acc: 0.9492 - val_loss: 0.0317 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03170, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 0s 12us/step - loss: 0.0375 - acc: 0.9870 - val_loss: 0.0219 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03170 to 0.02186, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0324 - acc: 0.9884 - val_loss: 0.0198 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02186 to 0.01978, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 0s 15us/step - loss: 0.0302 - acc: 0.9896 - val_loss: 0.0180 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01978 to 0.01799, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0306 - acc: 0.9891 - val_loss: 0.0171 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01799 to 0.01714, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0268 - acc: 0.9902 - val_loss: 0.0163 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01714 to 0.01631, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 0s 16us/step - loss: 0.0263 - acc: 0.9905 - val_loss: 0.0160 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01631 to 0.01596, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0260 - acc: 0.9915 - val_loss: 0.0155 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01596 to 0.01549, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0262 - acc: 0.9910 - val_loss: 0.0156 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0261 - acc: 0.9909 - val_loss: 0.0151 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01549 to 0.01514, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0265 - acc: 0.9909 - val_loss: 0.0155 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0260 - acc: 0.9905 - val_loss: 0.0159 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0253 - acc: 0.9909 - val_loss: 0.0149 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01514 to 0.01493, saving model to densenet169-tune0-best_weight.h5\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 0.0267 - acc: 0.9905 - val_loss: 0.0153 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0251 - acc: 0.9910 - val_loss: 0.0154 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.0244 - acc: 0.9922 - val_loss: 0.0149 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0242 - acc: 0.9914 - val_loss: 0.0157 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0237 - acc: 0.9914 - val_loss: 0.0161 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0242 - acc: 0.9914 - val_loss: 0.0152 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.0258 - acc: 0.9909 - val_loss: 0.0148 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01493 to 0.01484, saving model to densenet169-tune0-best_weight.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ba526a630>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并导出权重参数\n",
    "filepath=\"densenet169-tune0-best_weight.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, validation_split=0.2, shuffle=True,\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 0s 27us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengjun/DLND/Cat_vs_Dog/helper.py:130: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(index-1, 'label', y_test[i])\n"
     ]
    }
   ],
   "source": [
    "#在测试集上进行预测并导出预测值\n",
    "predict_on_model(test_data_dir, X_test, model, \"pred-densenet169-tune0.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这一模型在Kaggle上的得分为0.04590。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "我们将放开Densenet中的一些单元的权值，让它们是可学习的，以此训练我们的猫狗分类网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune freeze\n",
    "这里，我们首先在冻结全部权重情况下对全链接层进行训练。我们引入数据增强以获得更为泛化的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "0 input_2\n",
      "1 lambda_1\n",
      "2 zero_padding2d_1\n",
      "3 conv1/conv\n",
      "4 conv1/bn\n",
      "5 conv1/relu\n",
      "6 zero_padding2d_2\n",
      "7 pool1\n",
      "8 conv2_block1_0_bn\n",
      "9 conv2_block1_0_relu\n",
      "10 conv2_block1_1_conv\n",
      "11 conv2_block1_1_bn\n",
      "12 conv2_block1_1_relu\n",
      "13 conv2_block1_2_conv\n",
      "14 conv2_block1_concat\n",
      "15 conv2_block2_0_bn\n",
      "16 conv2_block2_0_relu\n",
      "17 conv2_block2_1_conv\n",
      "18 conv2_block2_1_bn\n",
      "19 conv2_block2_1_relu\n",
      "20 conv2_block2_2_conv\n",
      "21 conv2_block2_concat\n",
      "22 conv2_block3_0_bn\n",
      "23 conv2_block3_0_relu\n",
      "24 conv2_block3_1_conv\n",
      "25 conv2_block3_1_bn\n",
      "26 conv2_block3_1_relu\n",
      "27 conv2_block3_2_conv\n",
      "28 conv2_block3_concat\n",
      "29 conv2_block4_0_bn\n",
      "30 conv2_block4_0_relu\n",
      "31 conv2_block4_1_conv\n",
      "32 conv2_block4_1_bn\n",
      "33 conv2_block4_1_relu\n",
      "34 conv2_block4_2_conv\n",
      "35 conv2_block4_concat\n",
      "36 conv2_block5_0_bn\n",
      "37 conv2_block5_0_relu\n",
      "38 conv2_block5_1_conv\n",
      "39 conv2_block5_1_bn\n",
      "40 conv2_block5_1_relu\n",
      "41 conv2_block5_2_conv\n",
      "42 conv2_block5_concat\n",
      "43 conv2_block6_0_bn\n",
      "44 conv2_block6_0_relu\n",
      "45 conv2_block6_1_conv\n",
      "46 conv2_block6_1_bn\n",
      "47 conv2_block6_1_relu\n",
      "48 conv2_block6_2_conv\n",
      "49 conv2_block6_concat\n",
      "50 pool2_bn\n",
      "51 pool2_relu\n",
      "52 pool2_conv\n",
      "53 pool2_pool\n",
      "54 conv3_block1_0_bn\n",
      "55 conv3_block1_0_relu\n",
      "56 conv3_block1_1_conv\n",
      "57 conv3_block1_1_bn\n",
      "58 conv3_block1_1_relu\n",
      "59 conv3_block1_2_conv\n",
      "60 conv3_block1_concat\n",
      "61 conv3_block2_0_bn\n",
      "62 conv3_block2_0_relu\n",
      "63 conv3_block2_1_conv\n",
      "64 conv3_block2_1_bn\n",
      "65 conv3_block2_1_relu\n",
      "66 conv3_block2_2_conv\n",
      "67 conv3_block2_concat\n",
      "68 conv3_block3_0_bn\n",
      "69 conv3_block3_0_relu\n",
      "70 conv3_block3_1_conv\n",
      "71 conv3_block3_1_bn\n",
      "72 conv3_block3_1_relu\n",
      "73 conv3_block3_2_conv\n",
      "74 conv3_block3_concat\n",
      "75 conv3_block4_0_bn\n",
      "76 conv3_block4_0_relu\n",
      "77 conv3_block4_1_conv\n",
      "78 conv3_block4_1_bn\n",
      "79 conv3_block4_1_relu\n",
      "80 conv3_block4_2_conv\n",
      "81 conv3_block4_concat\n",
      "82 conv3_block5_0_bn\n",
      "83 conv3_block5_0_relu\n",
      "84 conv3_block5_1_conv\n",
      "85 conv3_block5_1_bn\n",
      "86 conv3_block5_1_relu\n",
      "87 conv3_block5_2_conv\n",
      "88 conv3_block5_concat\n",
      "89 conv3_block6_0_bn\n",
      "90 conv3_block6_0_relu\n",
      "91 conv3_block6_1_conv\n",
      "92 conv3_block6_1_bn\n",
      "93 conv3_block6_1_relu\n",
      "94 conv3_block6_2_conv\n",
      "95 conv3_block6_concat\n",
      "96 conv3_block7_0_bn\n",
      "97 conv3_block7_0_relu\n",
      "98 conv3_block7_1_conv\n",
      "99 conv3_block7_1_bn\n",
      "100 conv3_block7_1_relu\n",
      "101 conv3_block7_2_conv\n",
      "102 conv3_block7_concat\n",
      "103 conv3_block8_0_bn\n",
      "104 conv3_block8_0_relu\n",
      "105 conv3_block8_1_conv\n",
      "106 conv3_block8_1_bn\n",
      "107 conv3_block8_1_relu\n",
      "108 conv3_block8_2_conv\n",
      "109 conv3_block8_concat\n",
      "110 conv3_block9_0_bn\n",
      "111 conv3_block9_0_relu\n",
      "112 conv3_block9_1_conv\n",
      "113 conv3_block9_1_bn\n",
      "114 conv3_block9_1_relu\n",
      "115 conv3_block9_2_conv\n",
      "116 conv3_block9_concat\n",
      "117 conv3_block10_0_bn\n",
      "118 conv3_block10_0_relu\n",
      "119 conv3_block10_1_conv\n",
      "120 conv3_block10_1_bn\n",
      "121 conv3_block10_1_relu\n",
      "122 conv3_block10_2_conv\n",
      "123 conv3_block10_concat\n",
      "124 conv3_block11_0_bn\n",
      "125 conv3_block11_0_relu\n",
      "126 conv3_block11_1_conv\n",
      "127 conv3_block11_1_bn\n",
      "128 conv3_block11_1_relu\n",
      "129 conv3_block11_2_conv\n",
      "130 conv3_block11_concat\n",
      "131 conv3_block12_0_bn\n",
      "132 conv3_block12_0_relu\n",
      "133 conv3_block12_1_conv\n",
      "134 conv3_block12_1_bn\n",
      "135 conv3_block12_1_relu\n",
      "136 conv3_block12_2_conv\n",
      "137 conv3_block12_concat\n",
      "138 pool3_bn\n",
      "139 pool3_relu\n",
      "140 pool3_conv\n",
      "141 pool3_pool\n",
      "142 conv4_block1_0_bn\n",
      "143 conv4_block1_0_relu\n",
      "144 conv4_block1_1_conv\n",
      "145 conv4_block1_1_bn\n",
      "146 conv4_block1_1_relu\n",
      "147 conv4_block1_2_conv\n",
      "148 conv4_block1_concat\n",
      "149 conv4_block2_0_bn\n",
      "150 conv4_block2_0_relu\n",
      "151 conv4_block2_1_conv\n",
      "152 conv4_block2_1_bn\n",
      "153 conv4_block2_1_relu\n",
      "154 conv4_block2_2_conv\n",
      "155 conv4_block2_concat\n",
      "156 conv4_block3_0_bn\n",
      "157 conv4_block3_0_relu\n",
      "158 conv4_block3_1_conv\n",
      "159 conv4_block3_1_bn\n",
      "160 conv4_block3_1_relu\n",
      "161 conv4_block3_2_conv\n",
      "162 conv4_block3_concat\n",
      "163 conv4_block4_0_bn\n",
      "164 conv4_block4_0_relu\n",
      "165 conv4_block4_1_conv\n",
      "166 conv4_block4_1_bn\n",
      "167 conv4_block4_1_relu\n",
      "168 conv4_block4_2_conv\n",
      "169 conv4_block4_concat\n",
      "170 conv4_block5_0_bn\n",
      "171 conv4_block5_0_relu\n",
      "172 conv4_block5_1_conv\n",
      "173 conv4_block5_1_bn\n",
      "174 conv4_block5_1_relu\n",
      "175 conv4_block5_2_conv\n",
      "176 conv4_block5_concat\n",
      "177 conv4_block6_0_bn\n",
      "178 conv4_block6_0_relu\n",
      "179 conv4_block6_1_conv\n",
      "180 conv4_block6_1_bn\n",
      "181 conv4_block6_1_relu\n",
      "182 conv4_block6_2_conv\n",
      "183 conv4_block6_concat\n",
      "184 conv4_block7_0_bn\n",
      "185 conv4_block7_0_relu\n",
      "186 conv4_block7_1_conv\n",
      "187 conv4_block7_1_bn\n",
      "188 conv4_block7_1_relu\n",
      "189 conv4_block7_2_conv\n",
      "190 conv4_block7_concat\n",
      "191 conv4_block8_0_bn\n",
      "192 conv4_block8_0_relu\n",
      "193 conv4_block8_1_conv\n",
      "194 conv4_block8_1_bn\n",
      "195 conv4_block8_1_relu\n",
      "196 conv4_block8_2_conv\n",
      "197 conv4_block8_concat\n",
      "198 conv4_block9_0_bn\n",
      "199 conv4_block9_0_relu\n",
      "200 conv4_block9_1_conv\n",
      "201 conv4_block9_1_bn\n",
      "202 conv4_block9_1_relu\n",
      "203 conv4_block9_2_conv\n",
      "204 conv4_block9_concat\n",
      "205 conv4_block10_0_bn\n",
      "206 conv4_block10_0_relu\n",
      "207 conv4_block10_1_conv\n",
      "208 conv4_block10_1_bn\n",
      "209 conv4_block10_1_relu\n",
      "210 conv4_block10_2_conv\n",
      "211 conv4_block10_concat\n",
      "212 conv4_block11_0_bn\n",
      "213 conv4_block11_0_relu\n",
      "214 conv4_block11_1_conv\n",
      "215 conv4_block11_1_bn\n",
      "216 conv4_block11_1_relu\n",
      "217 conv4_block11_2_conv\n",
      "218 conv4_block11_concat\n",
      "219 conv4_block12_0_bn\n",
      "220 conv4_block12_0_relu\n",
      "221 conv4_block12_1_conv\n",
      "222 conv4_block12_1_bn\n",
      "223 conv4_block12_1_relu\n",
      "224 conv4_block12_2_conv\n",
      "225 conv4_block12_concat\n",
      "226 conv4_block13_0_bn\n",
      "227 conv4_block13_0_relu\n",
      "228 conv4_block13_1_conv\n",
      "229 conv4_block13_1_bn\n",
      "230 conv4_block13_1_relu\n",
      "231 conv4_block13_2_conv\n",
      "232 conv4_block13_concat\n",
      "233 conv4_block14_0_bn\n",
      "234 conv4_block14_0_relu\n",
      "235 conv4_block14_1_conv\n",
      "236 conv4_block14_1_bn\n",
      "237 conv4_block14_1_relu\n",
      "238 conv4_block14_2_conv\n",
      "239 conv4_block14_concat\n",
      "240 conv4_block15_0_bn\n",
      "241 conv4_block15_0_relu\n",
      "242 conv4_block15_1_conv\n",
      "243 conv4_block15_1_bn\n",
      "244 conv4_block15_1_relu\n",
      "245 conv4_block15_2_conv\n",
      "246 conv4_block15_concat\n",
      "247 conv4_block16_0_bn\n",
      "248 conv4_block16_0_relu\n",
      "249 conv4_block16_1_conv\n",
      "250 conv4_block16_1_bn\n",
      "251 conv4_block16_1_relu\n",
      "252 conv4_block16_2_conv\n",
      "253 conv4_block16_concat\n",
      "254 conv4_block17_0_bn\n",
      "255 conv4_block17_0_relu\n",
      "256 conv4_block17_1_conv\n",
      "257 conv4_block17_1_bn\n",
      "258 conv4_block17_1_relu\n",
      "259 conv4_block17_2_conv\n",
      "260 conv4_block17_concat\n",
      "261 conv4_block18_0_bn\n",
      "262 conv4_block18_0_relu\n",
      "263 conv4_block18_1_conv\n",
      "264 conv4_block18_1_bn\n",
      "265 conv4_block18_1_relu\n",
      "266 conv4_block18_2_conv\n",
      "267 conv4_block18_concat\n",
      "268 conv4_block19_0_bn\n",
      "269 conv4_block19_0_relu\n",
      "270 conv4_block19_1_conv\n",
      "271 conv4_block19_1_bn\n",
      "272 conv4_block19_1_relu\n",
      "273 conv4_block19_2_conv\n",
      "274 conv4_block19_concat\n",
      "275 conv4_block20_0_bn\n",
      "276 conv4_block20_0_relu\n",
      "277 conv4_block20_1_conv\n",
      "278 conv4_block20_1_bn\n",
      "279 conv4_block20_1_relu\n",
      "280 conv4_block20_2_conv\n",
      "281 conv4_block20_concat\n",
      "282 conv4_block21_0_bn\n",
      "283 conv4_block21_0_relu\n",
      "284 conv4_block21_1_conv\n",
      "285 conv4_block21_1_bn\n",
      "286 conv4_block21_1_relu\n",
      "287 conv4_block21_2_conv\n",
      "288 conv4_block21_concat\n",
      "289 conv4_block22_0_bn\n",
      "290 conv4_block22_0_relu\n",
      "291 conv4_block22_1_conv\n",
      "292 conv4_block22_1_bn\n",
      "293 conv4_block22_1_relu\n",
      "294 conv4_block22_2_conv\n",
      "295 conv4_block22_concat\n",
      "296 conv4_block23_0_bn\n",
      "297 conv4_block23_0_relu\n",
      "298 conv4_block23_1_conv\n",
      "299 conv4_block23_1_bn\n",
      "300 conv4_block23_1_relu\n",
      "301 conv4_block23_2_conv\n",
      "302 conv4_block23_concat\n",
      "303 conv4_block24_0_bn\n",
      "304 conv4_block24_0_relu\n",
      "305 conv4_block24_1_conv\n",
      "306 conv4_block24_1_bn\n",
      "307 conv4_block24_1_relu\n",
      "308 conv4_block24_2_conv\n",
      "309 conv4_block24_concat\n",
      "310 conv4_block25_0_bn\n",
      "311 conv4_block25_0_relu\n",
      "312 conv4_block25_1_conv\n",
      "313 conv4_block25_1_bn\n",
      "314 conv4_block25_1_relu\n",
      "315 conv4_block25_2_conv\n",
      "316 conv4_block25_concat\n",
      "317 conv4_block26_0_bn\n",
      "318 conv4_block26_0_relu\n",
      "319 conv4_block26_1_conv\n",
      "320 conv4_block26_1_bn\n",
      "321 conv4_block26_1_relu\n",
      "322 conv4_block26_2_conv\n",
      "323 conv4_block26_concat\n",
      "324 conv4_block27_0_bn\n",
      "325 conv4_block27_0_relu\n",
      "326 conv4_block27_1_conv\n",
      "327 conv4_block27_1_bn\n",
      "328 conv4_block27_1_relu\n",
      "329 conv4_block27_2_conv\n",
      "330 conv4_block27_concat\n",
      "331 conv4_block28_0_bn\n",
      "332 conv4_block28_0_relu\n",
      "333 conv4_block28_1_conv\n",
      "334 conv4_block28_1_bn\n",
      "335 conv4_block28_1_relu\n",
      "336 conv4_block28_2_conv\n",
      "337 conv4_block28_concat\n",
      "338 conv4_block29_0_bn\n",
      "339 conv4_block29_0_relu\n",
      "340 conv4_block29_1_conv\n",
      "341 conv4_block29_1_bn\n",
      "342 conv4_block29_1_relu\n",
      "343 conv4_block29_2_conv\n",
      "344 conv4_block29_concat\n",
      "345 conv4_block30_0_bn\n",
      "346 conv4_block30_0_relu\n",
      "347 conv4_block30_1_conv\n",
      "348 conv4_block30_1_bn\n",
      "349 conv4_block30_1_relu\n",
      "350 conv4_block30_2_conv\n",
      "351 conv4_block30_concat\n",
      "352 conv4_block31_0_bn\n",
      "353 conv4_block31_0_relu\n",
      "354 conv4_block31_1_conv\n",
      "355 conv4_block31_1_bn\n",
      "356 conv4_block31_1_relu\n",
      "357 conv4_block31_2_conv\n",
      "358 conv4_block31_concat\n",
      "359 conv4_block32_0_bn\n",
      "360 conv4_block32_0_relu\n",
      "361 conv4_block32_1_conv\n",
      "362 conv4_block32_1_bn\n",
      "363 conv4_block32_1_relu\n",
      "364 conv4_block32_2_conv\n",
      "365 conv4_block32_concat\n",
      "366 pool4_bn\n",
      "367 pool4_relu\n",
      "368 pool4_conv\n",
      "369 pool4_pool\n",
      "370 conv5_block1_0_bn\n",
      "371 conv5_block1_0_relu\n",
      "372 conv5_block1_1_conv\n",
      "373 conv5_block1_1_bn\n",
      "374 conv5_block1_1_relu\n",
      "375 conv5_block1_2_conv\n",
      "376 conv5_block1_concat\n",
      "377 conv5_block2_0_bn\n",
      "378 conv5_block2_0_relu\n",
      "379 conv5_block2_1_conv\n",
      "380 conv5_block2_1_bn\n",
      "381 conv5_block2_1_relu\n",
      "382 conv5_block2_2_conv\n",
      "383 conv5_block2_concat\n",
      "384 conv5_block3_0_bn\n",
      "385 conv5_block3_0_relu\n",
      "386 conv5_block3_1_conv\n",
      "387 conv5_block3_1_bn\n",
      "388 conv5_block3_1_relu\n",
      "389 conv5_block3_2_conv\n",
      "390 conv5_block3_concat\n",
      "391 conv5_block4_0_bn\n",
      "392 conv5_block4_0_relu\n",
      "393 conv5_block4_1_conv\n",
      "394 conv5_block4_1_bn\n",
      "395 conv5_block4_1_relu\n",
      "396 conv5_block4_2_conv\n",
      "397 conv5_block4_concat\n",
      "398 conv5_block5_0_bn\n",
      "399 conv5_block5_0_relu\n",
      "400 conv5_block5_1_conv\n",
      "401 conv5_block5_1_bn\n",
      "402 conv5_block5_1_relu\n",
      "403 conv5_block5_2_conv\n",
      "404 conv5_block5_concat\n",
      "405 conv5_block6_0_bn\n",
      "406 conv5_block6_0_relu\n",
      "407 conv5_block6_1_conv\n",
      "408 conv5_block6_1_bn\n",
      "409 conv5_block6_1_relu\n",
      "410 conv5_block6_2_conv\n",
      "411 conv5_block6_concat\n",
      "412 conv5_block7_0_bn\n",
      "413 conv5_block7_0_relu\n",
      "414 conv5_block7_1_conv\n",
      "415 conv5_block7_1_bn\n",
      "416 conv5_block7_1_relu\n",
      "417 conv5_block7_2_conv\n",
      "418 conv5_block7_concat\n",
      "419 conv5_block8_0_bn\n",
      "420 conv5_block8_0_relu\n",
      "421 conv5_block8_1_conv\n",
      "422 conv5_block8_1_bn\n",
      "423 conv5_block8_1_relu\n",
      "424 conv5_block8_2_conv\n",
      "425 conv5_block8_concat\n",
      "426 conv5_block9_0_bn\n",
      "427 conv5_block9_0_relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428 conv5_block9_1_conv\n",
      "429 conv5_block9_1_bn\n",
      "430 conv5_block9_1_relu\n",
      "431 conv5_block9_2_conv\n",
      "432 conv5_block9_concat\n",
      "433 conv5_block10_0_bn\n",
      "434 conv5_block10_0_relu\n",
      "435 conv5_block10_1_conv\n",
      "436 conv5_block10_1_bn\n",
      "437 conv5_block10_1_relu\n",
      "438 conv5_block10_2_conv\n",
      "439 conv5_block10_concat\n",
      "440 conv5_block11_0_bn\n",
      "441 conv5_block11_0_relu\n",
      "442 conv5_block11_1_conv\n",
      "443 conv5_block11_1_bn\n",
      "444 conv5_block11_1_relu\n",
      "445 conv5_block11_2_conv\n",
      "446 conv5_block11_concat\n",
      "447 conv5_block12_0_bn\n",
      "448 conv5_block12_0_relu\n",
      "449 conv5_block12_1_conv\n",
      "450 conv5_block12_1_bn\n",
      "451 conv5_block12_1_relu\n",
      "452 conv5_block12_2_conv\n",
      "453 conv5_block12_concat\n",
      "454 conv5_block13_0_bn\n",
      "455 conv5_block13_0_relu\n",
      "456 conv5_block13_1_conv\n",
      "457 conv5_block13_1_bn\n",
      "458 conv5_block13_1_relu\n",
      "459 conv5_block13_2_conv\n",
      "460 conv5_block13_concat\n",
      "461 conv5_block14_0_bn\n",
      "462 conv5_block14_0_relu\n",
      "463 conv5_block14_1_conv\n",
      "464 conv5_block14_1_bn\n",
      "465 conv5_block14_1_relu\n",
      "466 conv5_block14_2_conv\n",
      "467 conv5_block14_concat\n",
      "468 conv5_block15_0_bn\n",
      "469 conv5_block15_0_relu\n",
      "470 conv5_block15_1_conv\n",
      "471 conv5_block15_1_bn\n",
      "472 conv5_block15_1_relu\n",
      "473 conv5_block15_2_conv\n",
      "474 conv5_block15_concat\n",
      "475 conv5_block16_0_bn\n",
      "476 conv5_block16_0_relu\n",
      "477 conv5_block16_1_conv\n",
      "478 conv5_block16_1_bn\n",
      "479 conv5_block16_1_relu\n",
      "480 conv5_block16_2_conv\n",
      "481 conv5_block16_concat\n",
      "482 conv5_block17_0_bn\n",
      "483 conv5_block17_0_relu\n",
      "484 conv5_block17_1_conv\n",
      "485 conv5_block17_1_bn\n",
      "486 conv5_block17_1_relu\n",
      "487 conv5_block17_2_conv\n",
      "488 conv5_block17_concat\n",
      "489 conv5_block18_0_bn\n",
      "490 conv5_block18_0_relu\n",
      "491 conv5_block18_1_conv\n",
      "492 conv5_block18_1_bn\n",
      "493 conv5_block18_1_relu\n",
      "494 conv5_block18_2_conv\n",
      "495 conv5_block18_concat\n",
      "496 conv5_block19_0_bn\n",
      "497 conv5_block19_0_relu\n",
      "498 conv5_block19_1_conv\n",
      "499 conv5_block19_1_bn\n",
      "500 conv5_block19_1_relu\n",
      "501 conv5_block19_2_conv\n",
      "502 conv5_block19_concat\n",
      "503 conv5_block20_0_bn\n",
      "504 conv5_block20_0_relu\n",
      "505 conv5_block20_1_conv\n",
      "506 conv5_block20_1_bn\n",
      "507 conv5_block20_1_relu\n",
      "508 conv5_block20_2_conv\n",
      "509 conv5_block20_concat\n",
      "510 conv5_block21_0_bn\n",
      "511 conv5_block21_0_relu\n",
      "512 conv5_block21_1_conv\n",
      "513 conv5_block21_1_bn\n",
      "514 conv5_block21_1_relu\n",
      "515 conv5_block21_2_conv\n",
      "516 conv5_block21_concat\n",
      "517 conv5_block22_0_bn\n",
      "518 conv5_block22_0_relu\n",
      "519 conv5_block22_1_conv\n",
      "520 conv5_block22_1_bn\n",
      "521 conv5_block22_1_relu\n",
      "522 conv5_block22_2_conv\n",
      "523 conv5_block22_concat\n",
      "524 conv5_block23_0_bn\n",
      "525 conv5_block23_0_relu\n",
      "526 conv5_block23_1_conv\n",
      "527 conv5_block23_1_bn\n",
      "528 conv5_block23_1_relu\n",
      "529 conv5_block23_2_conv\n",
      "530 conv5_block23_concat\n",
      "531 conv5_block24_0_bn\n",
      "532 conv5_block24_0_relu\n",
      "533 conv5_block24_1_conv\n",
      "534 conv5_block24_1_bn\n",
      "535 conv5_block24_1_relu\n",
      "536 conv5_block24_2_conv\n",
      "537 conv5_block24_concat\n",
      "538 conv5_block25_0_bn\n",
      "539 conv5_block25_0_relu\n",
      "540 conv5_block25_1_conv\n",
      "541 conv5_block25_1_bn\n",
      "542 conv5_block25_1_relu\n",
      "543 conv5_block25_2_conv\n",
      "544 conv5_block25_concat\n",
      "545 conv5_block26_0_bn\n",
      "546 conv5_block26_0_relu\n",
      "547 conv5_block26_1_conv\n",
      "548 conv5_block26_1_bn\n",
      "549 conv5_block26_1_relu\n",
      "550 conv5_block26_2_conv\n",
      "551 conv5_block26_concat\n",
      "552 conv5_block27_0_bn\n",
      "553 conv5_block27_0_relu\n",
      "554 conv5_block27_1_conv\n",
      "555 conv5_block27_1_bn\n",
      "556 conv5_block27_1_relu\n",
      "557 conv5_block27_2_conv\n",
      "558 conv5_block27_concat\n",
      "559 conv5_block28_0_bn\n",
      "560 conv5_block28_0_relu\n",
      "561 conv5_block28_1_conv\n",
      "562 conv5_block28_1_bn\n",
      "563 conv5_block28_1_relu\n",
      "564 conv5_block28_2_conv\n",
      "565 conv5_block28_concat\n",
      "566 conv5_block29_0_bn\n",
      "567 conv5_block29_0_relu\n",
      "568 conv5_block29_1_conv\n",
      "569 conv5_block29_1_bn\n",
      "570 conv5_block29_1_relu\n",
      "571 conv5_block29_2_conv\n",
      "572 conv5_block29_concat\n",
      "573 conv5_block30_0_bn\n",
      "574 conv5_block30_0_relu\n",
      "575 conv5_block30_1_conv\n",
      "576 conv5_block30_1_bn\n",
      "577 conv5_block30_1_relu\n",
      "578 conv5_block30_2_conv\n",
      "579 conv5_block30_concat\n",
      "580 conv5_block31_0_bn\n",
      "581 conv5_block31_0_relu\n",
      "582 conv5_block31_1_conv\n",
      "583 conv5_block31_1_bn\n",
      "584 conv5_block31_1_relu\n",
      "585 conv5_block31_2_conv\n",
      "586 conv5_block31_concat\n",
      "587 conv5_block32_0_bn\n",
      "588 conv5_block32_0_relu\n",
      "589 conv5_block32_1_conv\n",
      "590 conv5_block32_1_bn\n",
      "591 conv5_block32_1_relu\n",
      "592 conv5_block32_2_conv\n",
      "593 conv5_block32_concat\n",
      "594 bn\n",
      "595 avg_pool\n",
      "596 dropout_2\n",
      "597 dense_2\n"
     ]
    }
   ],
   "source": [
    "#构造模型\n",
    "x_input = Input((224, 224, 3))\n",
    "x_input = Lambda(densenet.preprocess_input)(x_input)\n",
    "\n",
    "base_model = DenseNet169(input_tensor=x_input, weights='imagenet', include_top=False, pooling = 'avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = Dropout(0.5)(base_model.output)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(base_model.input, x)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=90,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True)\n",
    "val_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow_from_directory(train_data_dir, (224, 224),shuffle=True, \n",
    "                                          batch_size=64,class_mode='binary')\n",
    "valid_generator = val_gen.flow_from_directory(valid_data_dir, (224, 224), shuffle=True, \n",
    "                                          batch_size=32,class_mode='binary')\n",
    "for i in range(len(model.layers)):\n",
    "    print(i,model.layers[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 604s 483ms/step - loss: 0.1579 - acc: 0.9347 - val_loss: 0.0995 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09952, saving model to densenet169-best_weight_freeze.h5\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 603s 483ms/step - loss: 0.1374 - acc: 0.9450 - val_loss: 0.0770 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09952 to 0.07704, saving model to densenet169-best_weight_freeze.h5\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 602s 482ms/step - loss: 0.1340 - acc: 0.9459 - val_loss: 0.0773 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 600s 480ms/step - loss: 0.1348 - acc: 0.9467 - val_loss: 0.1010 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 599s 479ms/step - loss: 0.1342 - acc: 0.9463 - val_loss: 0.0751 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07704 to 0.07514, saving model to densenet169-best_weight_freeze.h5\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 602s 481ms/step - loss: 0.1347 - acc: 0.9458 - val_loss: 0.0819 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 601s 481ms/step - loss: 0.1314 - acc: 0.9470 - val_loss: 0.1209 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 605s 484ms/step - loss: 0.1373 - acc: 0.9445 - val_loss: 0.0966 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 603s 482ms/step - loss: 0.1339 - acc: 0.9461 - val_loss: 0.0841 - val_acc: 0.9704\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 604s 483ms/step - loss: 0.1326 - acc: 0.9461 - val_loss: 0.0661 - val_acc: 0.9754\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.07514 to 0.06607, saving model to densenet169-best_weight_freeze.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a90f267b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "filepath=\"densenet169-best_weight_freeze.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1250,\n",
    "        epochs=10,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=150,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:38<00:00, 320.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 93s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:183: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 241320.46it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_densenet(12500, 224, 224, test_data_dir, model, \"densenet169-best_weight_freeze.h5\", \"pred-densenet169-freeze.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这个模型在kaggle的得分是0.08211。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning 1\n",
    "对于densenet模型，我们值tuning一个denseblock。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in model.layers[370:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.load_weights('densenet169-best_weight_freeze.h5')\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 655s 524ms/step - loss: 0.0776 - acc: 0.9708 - val_loss: 0.0254 - val_acc: 0.9923\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02539, saving model to densenet169-best_weight_fine_tuning-1.h5\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 656s 525ms/step - loss: 0.0459 - acc: 0.9827 - val_loss: 0.0602 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 655s 524ms/step - loss: 0.0359 - acc: 0.9865 - val_loss: 0.0215 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02539 to 0.02154, saving model to densenet169-best_weight_fine_tuning-1.h5\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 656s 525ms/step - loss: 0.0277 - acc: 0.9898 - val_loss: 0.0352 - val_acc: 0.9901\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 656s 525ms/step - loss: 0.0235 - acc: 0.9913 - val_loss: 0.0304 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 656s 525ms/step - loss: 0.0217 - acc: 0.9920 - val_loss: 0.0492 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 657s 525ms/step - loss: 0.0178 - acc: 0.9937 - val_loss: 0.0504 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 654s 523ms/step - loss: 0.0161 - acc: 0.9943 - val_loss: 0.0455 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 654s 524ms/step - loss: 0.0137 - acc: 0.9950 - val_loss: 0.0267 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 655s 524ms/step - loss: 0.0147 - acc: 0.9950 - val_loss: 0.0391 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a90d6ef28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型并保存在验证集上损失函数最小的权重\n",
    "filepath=\"densenet169-best_weight_fine_tuning-1.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1250,\n",
    "        epochs=10,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=300,\n",
    "        callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:39<00:00, 319.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 94s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12500 [00:00<?, ?it/s]/home/pengjun/DLND/Cat_vs_Dog/helper.py:183: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  df.set_value(i, 'label', y_test[i])\n",
      "100%|██████████| 12500/12500 [00:00<00:00, 248676.90it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_on_densenet(12500, 224, 224, test_data_dir, model, \"densenet169-best_weight_fine_tuning-1.h5\", \"pred-densenet169-fine_tuning-1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这一轮Tuning的最终得分为：0.04314。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save_weights(\"fine_tuned_densenet169.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
